[[overview]]
== Overview

//-------Remove after TC approval-------

Readers should consider the following warning.

WARNING: This document defines a draft OGC Best Practice on a particular technology or approach. This document is not an OGC Standard and may not be referred to as an OGC Standard (yet). This document is not an official position of the OGC.

//----------------------------------------

=== Introduction to JSON

This section presents the JavaScript Object Notation (JSON). Afterwards, it discusses important questions such as what JSON offers, when a JSON encoding offers an advantage (e.g. in simplicity and performance) in comparison to an eXtensible Markup Language (XML) encoding, and when XML encodings can provide a better solution (e.g. adding more expressivity and robustness). Finally it presents some suggestions of what OGC can add on top of the basic JSON definition to ensure better geospatial interoperability of applications using JSON.

[[The_JSON_format]]
=== The JSON format

JSON is a simple data model that can represent four primitives (strings, numbers, booleans (_true_ or _false_) and _null_) and includes two structured types (objects and arrays). Strings are enclosed in _quotation marks_, numbers do not have quotation marks, objects are enclosed in curly brackets "{}" and arrays are enclosed in square brackets "[]". An object is an unordered collection of zero or more properties (name and value pairs, separated by a colon), where a name is a string and a value is a primitive or a structured type. Properties are separated by commas (usually each of them is written on a different line but this is not required). An array is an ordered sequence of zero or more values (primitives or structured types, separated by commas) with no explicit indication of the sequence number.

The fact that the names of properties are enclosed in _quotation marks_ and the use of ":" are marks of identity that help to visually identify that text documents are actually instances written in JSON (instead of e.g. C++ or Java data structures).

.Example of JSON document providing some metadata about a picture.
[source,json]
----
{
    "width":  800,
    "height": 600,
    "title":  "View from 15th Floor",
    "thumbnail": {
        "url":    "http://www.example.com/image/481989943",
        "height": 125,
        "width":  100
    },
    "animated" : false,
    "ids": [116, 943, 234, 38793]
}
----

In the example above, a _picture_ is represented as an object with two numerical properties ("width" and "height"), a string property ("title"), an object property ("thumbnail"), a boolean property ("animated") and an array of numbers as a property ("ids"). Nothing in the document indicates that it is describing a _picture_. The reason is that we are supposed to assign the data structure to a variable the name of which will tell us what the variable is about. This is shown in the example below.

.Assigning a JSON structure to a variable in JavaScript
[source,javascript]
----
picture={
    "width":  800,
    "height": 600,
    "title":  "View from 15th Floor",
    "thumbnail": {
        "url":    "http://www.example.com/image/481989943",
        "height": 125,
        "width":  100
    },
    "animated" : false,
    "ids": [116, 943, 234, 38793]
}
----

See the Section <<KVP_GET_client_request>> for the way to incorporate a JSON document into JavaScript code on the fly.

=== If we had XML, why do we need JSON?
In the web, we find several comparisons between XML and JSON, some of them trying to do statistical analysis on some criteria, such as verbosity or performance. Some others (many, actually) are more based on opinions than in facts. This document will try to escape this debate and focus on practical facts.

XML was designed by a consensus process in several Internet groups and became a W3C recommendation on February 10th, 1998 as a document standard completely independent from any programming language. Since then, hundreds of document formats based on XML syntax have been proposed, including Really Simple Syndication (RSS), Atom, Simple Object Access Protocol (SOAP), and Extensible Hypertext Markup Language(XHTML), Office Open XML, OpenOffice.org, Microsoft .NET Framework and many others. OGC has adopted XML for many of its web service messages and for several data formats, including the Geography Markup Language(GML), WaterML, Sensor Model Language (SensorML), Geospatial User Feedback (GUF), etc. XML has some interesting additional components: XML Schema/RelaxNG/Schematron provide ways to restrict the classes and data types to a controlled set of them. Actually, all document formats cited before provide a some form of schema document that accompanies the standard document. By providing schema files, standards incorporate a direct way to check conformance of a XML document to a standard data model: a process executed by automatic tools that is called "XML validation". Other components of XML family are XPath (a query language), Extensible Stylesheet Language Transformations (XSLT), etc. With time, these components have been implemented in many programming languages and tools.

JSON history is completely different. JSON was introduced in 1999 as a subset of the JavaScript language that extracted the essentials for defining data structures. This original idea is stated in the RFC7159: "JSON's design goals were to be minimal, portable, textual, and a subset of JavaScript". After 2005, JSON became popular and is used in the Application Programing Interfaces (APIs) of many web services, including those of well-known companies such as Yahoo! or Google. Currently, JSON is no longer restricted to web browsers, because JavaScript can now be used in web services and in standalone applications (e.g. using node.js) and also because there are libraries that can read and write JSON for almost every programming language (see a long list of programming languages that have some sort of JSON libraries at http://json.org).

==== The secret of JSON success in the web

AS we said, this is a matter of opinion and even taste but there are some practical reasons that have helped to make JSON the favorite data encoding for many people.

* XML is not easy to learn. JSON format is so simple that it can be explained in a few lines (as has been done in <<The_JSON_format>>). In contrast, XML requires some knowledge about namespaces and namespace combinations. It also requires some knowledge about classes, complex data types, class generalizations, etc. None of this is currently present in JSON in its basic form.
* XML is defined to be extensible, but XSD Schema validation is very restrictive in extensibility (at least in the way it is used in the OGC standards). In practice, extension points need to be "prepared" by the designer of the original standard to be extended. For example, adding an element to a class in a non-initially foreseen place results in an error during validation. In many occasions the only solution is changing the class name by generalization, giving up descend compatibility. In that sense, RelaxNG validation was designed with extensibility in mind, but is not commonly used yet (it is now the recommended validation language for Atom feeds and OWS Context Atom encoding). JSON is used in a way that it can be extended (e.g. adding properties to objects is allowed without breaking compatibility). By default, JSON schema (see <<JSON_Schema>>) respects this extensibility.
* JSON relies on the simplicity of JavaScript in three important ways:
** JSON (and JavaScript) have a very limited set of data types. All numbers are "Number" (there is no distinction between float, integer, long, byte,...) and all strings are "String". Arrays and Objects are almost identical; actually Arrays are Objects with numerical consecutive property names.
** In JavaScript, a JSON document can be converted in an JavaScript data structure (e.g. an object tree) with a single function, instead of a complicated chain of XML DOM data access function calls for each property needed to extract from an XML document. Unfortunately, this has nothing to do with XML or JSON, but in the way the XML DOM was initially implemented. Nevertheless, it has influenced the view that "JSON is simple; XML is complicated". To make the situation worst, XML DOM function implementations are relatively slow compared to other JavaScript libraries and tend to collapse when parsing big files, making scalability a performance issue.
** Libraries have issues with long (URI like ones) and short namespaces (alies like ones). Only the long namespace is fixed and globally and uniquely represent the namespace. Short namespace may vary from one instance to the next instance. A GML 3.0 file has a constant long namespace but the short namespace could be anything ("gml", "gml3", "gml30",...). Since node names and xpath expressions use a combination of the short namespace and the name of the element, they are instance dependent. Some lirearies use long namespaces but are not browser compatible yet.
** JSON objects do not rely on explicit classes and data types. Even the concept of "data constructor" that was present in early versions of JavaScript it is not recommended anymore (with exceptions). Objects are created on-the-fly and potentially all objects in JSON (and in JavaScript) have a different data structure. However, in practical implementations, many objects in object arrays will share the same common pattern.
** JSON objects can be direct inputs of JavaScript API functions providing a very easy solution for extensibility of APIs. All JavaScript functions can potentially have a very limited number of properties, if some of them are JSON objects. New optional properties can be introduced to these objects without changing the API.

As you will discover in the next sections of this document, a rigorous application of JSON in OGC services will require adoption of new additions to JSON, such as JSON validation and JSON-LD resulting in a not-so-simple JSON utilization that in contrast will result in a more predictable ans interoperable instances.

=== JSON or YAML
Any text notation needs to make a decision on how to encode strings, sentences, blocks and inclusions. There are two main approaches:
* Introduction of some markup that defines blocks and end-of-sentences.
* The mandatory use of indentation (tabs) and new lines to define blocks and end-of-sentences.

For example, C requires curly brackets "{}" to mark blocks "" to enclose strings and ";"" to end sentences but allow for arbitrary indentation and lining. JavaScript (that was deeply inspired by the C notation) uses {} for blocks, "" for strings and considers ; an optional end-of-sentence mask. This decisions has the advantage that makes spaces, tabs and new-line marks completely unnecessary for a machine to understand the code. Nevertheless, any book on structured programing recommends the use of new-lines to separate sentences, and indentations to make blocks more visible and easy to read for humans. In contrast Python requires the use of new-lines and indentations to define sentences and blocks, removing the need for many markup symbols, resulting in a code less filled with symbols and more human readable.

In our experience, both approaches require equal time of mental training to be able to read and understand the code. In contrast, you can argue that code that does not require markup is easier to write and does not need constant attention to carefully closing markup resulting in less syntactic errors.

JSON was defined as a subset of JavaScript and it inherits the need for markup. Object blocks require {}, Array blocks require [], and properties requires and end-of-element "," except for the last one in a block. JSON parameter names require "" as well as string values (this is a difference with pure JavaScript data structures). All this generates a code with a high number of symbols. Even if JSON syntax was considered simple in the previous section, it is also true that it is difficult to create a syntactically valid JSON file without an editor that uses syntax coloring and some JSON syntax validation tool. JSON syntax validation tools help a human writer to ensure that the code is syntactically correct. This makes manually writing JSON files manually a tedious job.

YAML (meaning: Ain't Markup Language) is defined as an alternative encoding, that has very similar capabilities than JSON but it requires considerably less markup. In contrast, blocks require indentation and properties need to be in different lines (and if they are parts of an array, be preceded by a '-'). It is a rare exception among text encoding, where even strings does not require quotation marks. YAML can represent most of the JSON features and has additional features lacking in JSON, including: comments, extensible data types, relational anchors, and mapping types preserving key order. Starting from a JSON file, you can transform a JSON file to YAML and back without losing anything. There are several on-line JSON to YAML converters in the web such as: https://www.json2yaml.com.

This is how our first JSON example looks like in YAML:

[source,yaml]
----
---
width: 800
height: 600
title: View from 15th Floor
thumbnail:
  url: http://www.example.com/image/481989943
  height: 125
  width: 100
animated: false
ids:
- 116
- 943
- 234
- 38793
----

In considering YAML as an alternative to JSON, there are two aspects to take into consideration:
* At the time of writing this document, YAML has no schema like validation language but JSON does have an advanced draft "JSON schema" validation (tht will be presented in a following section). Having a validation schema is considered particularly important for the standardization process, providing a starting point for writing a conformance test.
* OpenAPI uses YAML as the main format for documenting APIs. JSON is considered a direct alternative but common examples of OpenAPI documents are mainly found in JSON and the Swagger editor uses YAML.

Considering both factors, this document recommends to favor JSON for all the encoding of data types and consider YAML an automatic alternative that is always possible but should not need to be emphasized or promoted. In contrast, this document recommends the use of YAML for OpenAPI descriptions of APIs (following what is already a common practice in the web) and consider JSON an automatic alternative that is always possible but should not need to be emphasized.

As a curiosity, OpenAPI included a OpenAPI schema language to specify the data model used for complex request payloads and response. This language is deeply inspired in JSON Schema (with some differences: see https://swagger.io/docs/specification/data-models/keywords/) but paradoxically, it is commonly encoded in YAML in fragments of OpenAPI documents.
